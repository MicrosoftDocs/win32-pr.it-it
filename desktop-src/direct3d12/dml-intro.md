---
title: Introduzione a DirectML
description: Direct Machine Learning (DirectML) è un'API di basso livello per Machine Learning (ML).
ms.custom: Windows 10 May 2019 Update
ms.localizationpriority: high
ms.topic: article
ms.date: 04/19/2019
ms.openlocfilehash: 2dd37bc4c27364e26e4bbd4ae2cf5d43031c3314
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 09/16/2019
ms.locfileid: "74104559"
---
# <a name="introduction-to-directml"></a><span data-ttu-id="e9aa4-103">Introduzione a DirectML</span><span class="sxs-lookup"><span data-stu-id="e9aa4-103">Introduction to DirectML</span></span>

## <a name="summary"></a><span data-ttu-id="e9aa4-104">Riepilogo</span><span class="sxs-lookup"><span data-stu-id="e9aa4-104">Summary</span></span>

<span data-ttu-id="e9aa4-105">Direct Machine Learning (DirectML) è un'API di basso livello per Machine Learning (ML).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-105">Direct Machine Learning (DirectML) is a low-level API for machine learning (ML).</span></span> <span data-ttu-id="e9aa4-106">Le primitive di Machine Learning con accelerazione hardware (detti operatori) sono i blocchi predefiniti di DirectML.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-106">Hardware-accelerated machine learning primitives (called operators) are the building blocks of DirectML.</span></span> <span data-ttu-id="e9aa4-107">Da questi blocchi predefiniti è possibile sviluppare tecniche di apprendimento automatico come il ridimensionamento, l'anti-aliasing e il trasferimento dello stile, a un nome ma solo alcuni.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-107">From those building blocks, you can develop such machine learning techniques as upscaling, anti-aliasing, and style transfer, to name but a few.</span></span> <span data-ttu-id="e9aa4-108">Denoising e super-risoluzione, ad esempio, consentono di ottenere effetti raytraced impressionanti con un minor numero di raggi per pixel.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-108">Denoising and super-resolution, for example, allow you to achieve impressive raytraced effects with fewer rays per pixel.</span></span>

<span data-ttu-id="e9aa4-109">È possibile integrare i carichi di lavoro del machine learning nel gioco, nel motore, nel middleware, nel back-end o in un'altra applicazione.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-109">You can integrate machine learning inferencing workloads into your game, engine, middleware, backend, or other application.</span></span> <span data-ttu-id="e9aa4-110">DirectML dispone di un flusso di lavoro e di un'interfaccia di programmazione di tipo DirectX 12 (C++ nativo, Nano-COM) e supportato da tutti i componenti hardware compatibili con DirectX 12.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-110">DirectML has a familiar (native C++, nano-COM) DirectX 12-style programming interface and workflow, and it's supported by all DirectX 12-compatible hardware.</span></span> <span data-ttu-id="e9aa4-111">Per le applicazioni di esempio DirectML, incluso un esempio di un'applicazione DirectML minima, vedere [applicazioni di esempio DirectML](dml-min-app.md).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-111">For DirectML sample applications, including a sample of a minimal DirectML application, see [DirectML sample applications](dml-min-app.md).</span></span>

<span data-ttu-id="e9aa4-112">DirectML è stato introdotto in Windows 10, versione 1903 e nella versione corrispondente del Windows SDK.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-112">DirectML is introduced in Windows 10, version 1903, and in the corresponding version of the Windows SDK.</span></span>

## <a name="is-directml-appropriate-for-my-project"></a><span data-ttu-id="e9aa4-113">DirectML è appropriato per il progetto?</span><span class="sxs-lookup"><span data-stu-id="e9aa4-113">Is DirectML appropriate for my project?</span></span>

<span data-ttu-id="e9aa4-114">DirectML è un componente di [Windows Machine Learning](/windows/ai) Umbrella.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-114">DirectML is a component under the [Windows Machine Learning](/windows/ai) umbrella.</span></span> <span data-ttu-id="e9aa4-115">L'API WinML di livello superiore è principalmente incentrata sul modello, con il flusso di lavoro Load-bind-Evaluate.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-115">The higher-level WinML API is primarily model-focused, with its load-bind-evaluate workflow.</span></span> <span data-ttu-id="e9aa4-116">Tuttavia, per sfruttare al meglio il silicio, domini come giochi e motori richiedono in genere un livello di astrazione inferiore e un livello superiore di controllo dello sviluppatore.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-116">But domains such as games and engines typically need a lower level of abstraction, and a higher degree of developer control, in order to take full advantage of the silicon.</span></span> <span data-ttu-id="e9aa4-117">Se si contano i millisecondi e si spremeno i tempi dei fotogrammi, DirectML soddisferà le esigenze di machine learning.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-117">If you're counting milliseconds, and squeezing frame times, then DirectML will meet your machine learning needs.</span></span>

<span data-ttu-id="e9aa4-118">Per scenari affidabili in tempo reale, a prestazioni elevate, a bassa latenza e/o con vincoli di risorse, usare DirectML (anziché WinML).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-118">For reliable real-time, high-performance, low-latency, and/or resource-constrained scenarios, use DirectML (rather than WinML).</span></span> <span data-ttu-id="e9aa4-119">È possibile integrare DirectML direttamente nel motore esistente o nella pipeline di rendering.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-119">You can integrate DirectML directly into your existing engine or rendering pipeline.</span></span> <span data-ttu-id="e9aa4-120">In alternativa, a un livello superiore per i Framework e il middleware personalizzati di Machine Learning, DirectML può offrire un back-end a prestazioni elevate in Windows.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-120">Or, at a higher level for custom machine learning frameworks and middleware, DirectML can provide a high-performance backend on Windows.</span></span>

<span data-ttu-id="e9aa4-121">WinML viene implementato utilizzando DirectML come uno dei relativi backend.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-121">WinML is itself implemented using DirectML as one of its backends.</span></span>

## <a name="what-work-does-directml-do-and-what-work-must-i-do-as-the-developer"></a><span data-ttu-id="e9aa4-122">Operazioni eseguite da DirectML; e quali operazioni è *necessario eseguire* come sviluppatore?</span><span class="sxs-lookup"><span data-stu-id="e9aa4-122">What work does DirectML do; and what work must *I* do as the developer?</span></span>

<span data-ttu-id="e9aa4-123">DirectML esegue in modo efficiente i singoli livelli del modello di inferenza sulla GPU (o sui core di accelerazione AI, se presenti).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-123">DirectML efficiently executes the individual layers of your inference model on the GPU (or on AI-acceleration cores, if present).</span></span> <span data-ttu-id="e9aa4-124">Ogni livello è un operatore e DirectML fornisce una libreria di operatori primitivi di Machine Learning con accelerazione hardware di basso livello.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-124">Each layer is an operator, and DirectML provides you with a library of low-level, hardware-accelerated machine learning primitive operators.</span></span> <span data-ttu-id="e9aa4-125">Questi operatori hanno ottimizzazioni specifiche per l'hardware e per l'architettura progettate in a loro (più avanti nella sezione [perché DirectML esegue correttamente?](#why-does-directml-perform-so-well)).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-125">These operators have hardware-specific and architecture-specific optimizations designed in to them (more on that in the section [Why does DirectML perform so well?](#why-does-directml-perform-so-well)).</span></span> <span data-ttu-id="e9aa4-126">Allo stesso tempo, lo sviluppatore vedrà una singola interfaccia indipendente dal fornitore per l'esecuzione di tali operatori.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-126">At the same time, you as the developer see a single, vendor-agnostic interface for executing those operators.</span></span>

<span data-ttu-id="e9aa4-127">La libreria di operatori in DirectML fornisce tutte le operazioni usuali che ci si aspetterebbe di poter usare in un carico di lavoro di machine learning.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-127">The library of operators in DirectML supplies all of the usual operations that you'd expect to be able to use in a machine learning workload.</span></span>

- <span data-ttu-id="e9aa4-128">Operatori di attivazione, ad esempio **Linear**, **ReLU**, **Sigma**, **tanh** e altro ancora.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-128">Activation operators, such as **linear**, **ReLU**, **sigmoid**, **tanh**, and more.</span></span>
- <span data-ttu-id="e9aa4-129">Operatori per elementi, ad esempio **Add**, **Exp**, **log**, **Max**, **min**, **Sub** e altro ancora.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-129">Element-wise operators, such as **add**, **exp**, **log**, **max**, **min**, **sub**, and more.</span></span>
- <span data-ttu-id="e9aa4-130">Operatori di convoluzione, ad esempio **convoluzione** 2D e 3D e altro ancora.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-130">Convolution operators, such as 2D and 3D **convolution**, and more.</span></span>
- <span data-ttu-id="e9aa4-131">Operatori di riduzione, ad esempio **argmin**, **Average**, **L2**, **Sum** e altro ancora.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-131">Reduction operators, such as **argmin**, **average**, **l2**, **sum**, and more.</span></span>
- <span data-ttu-id="e9aa4-132">Operatori di pooling, ad esempio **Average**, **LP** e **Max**.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-132">Pooling operators, such as **average**, **lp**, and **max**.</span></span>
- <span data-ttu-id="e9aa4-133">Operatori Neural Network (NN), ad esempio **GEMM**, **gru**, **LSTM** e **RNN**.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-133">Neural network (NN) operators, such as **gemm**, **gru**, **lstm**, and **rnn**.</span></span>
- <span data-ttu-id="e9aa4-134">E molti altri.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-134">And many more.</span></span>

<span data-ttu-id="e9aa4-135">Per ottenere prestazioni ottimali e non pagare per ciò che non si usa, DirectML mette il controllo in mano come sviluppatore sulla modalità di esecuzione del carico di lavoro di Machine Learning sull'hardware.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-135">For maximal performance, and so that you don't pay for what you don't use, DirectML puts the control into your hands as a developer over how your machine learning workload is executed on the hardware.</span></span> <span data-ttu-id="e9aa4-136">Scoprire quali operatori eseguire e quando è responsabilità dello sviluppatore.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-136">Figuring out which operators to execute, and when, is your responsibility as the developer.</span></span> <span data-ttu-id="e9aa4-137">Le attività che si lasciano a discrezione includono: la trascrizione del modello; semplificazione e ottimizzazione dei livelli; caricamento dei pesi; allocazione delle risorse, associazione, gestione della memoria (analogamente a Direct3D 12); ed esecuzione del grafo.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-137">Tasks that are left to your discretion include: transcribing the model; simplifying and optimizing your layers; loading weights; resource allocation, binding, memory management (just as with Direct3D 12); and execution of the graph.</span></span>

<span data-ttu-id="e9aa4-138">Si conservano informazioni di alto livello sui grafici (è possibile impostare il modello a livello di codice direttamente oppure è possibile scrivere un caricatore del modello personalizzato).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-138">You retain high-level knowledge of your graphs (you can hard-code your model directly, or you can write your own model loader).</span></span> <span data-ttu-id="e9aa4-139">È possibile progettare un modello di scalabilità orizzontale, ad esempio, usando diversi livelli ciascuno degli operatori di **ricampionamento**, **convoluzione**, **normalizzazione** e **attivazione** .</span><span class="sxs-lookup"><span data-stu-id="e9aa4-139">You might design an upscaling model, for example, using several layers each of **upsample**, **convolution**, **normalization**, and **activation** operators.</span></span> <span data-ttu-id="e9aa4-140">Con una certa familiarità, una pianificazione attenta e una gestione delle barriere, è possibile estrarre il massimo parallelismo e le prestazioni dell'hardware.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-140">With that familiarity, careful scheduling, and barrier management, you can extract the most parallelism and performance from the hardware.</span></span> <span data-ttu-id="e9aa4-141">Se si sta sviluppando un gioco, l'accurata gestione delle risorse e il controllo sulla pianificazione consentono di Interleave sui carichi di lavoro di machine learning e sul lavoro di rendering tradizionale per saturare la GPU.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-141">If you're developing a game, then your careful resource management and control over scheduling enables you to interleave machine learning workloads and traditional rendering work in order to saturate the GPU.</span></span>

## <a name="whats-the-high-level-directml-workflow"></a><span data-ttu-id="e9aa4-142">Qual è il flusso di lavoro DirectML di alto livello?</span><span class="sxs-lookup"><span data-stu-id="e9aa4-142">What's the high-level DirectML workflow?</span></span>

<span data-ttu-id="e9aa4-143">Ecco la ricetta generale per il modo in cui si prevede di usare DirectML.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-143">Here's the high-level recipe for how we expect DirectML to be used.</span></span> <span data-ttu-id="e9aa4-144">All'interno delle due fasi principali di inizializzazione ed esecuzione, è possibile registrare il lavoro in elenchi di comandi e quindi eseguirli in una coda.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-144">Within the two main phases of initialization and execution, you record work into command lists and then you execute them on a queue.</span></span>

### <a name="initialization"></a><span data-ttu-id="e9aa4-145">Inizializzazione</span><span class="sxs-lookup"><span data-stu-id="e9aa4-145">Initialization</span></span>

1. <span data-ttu-id="e9aa4-146">Creare le risorse Direct3D 12 &mdash; il dispositivo Direct3D 12, la coda di comandi, l'elenco dei comandi e le risorse come gli heap dei descrittori.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-146">Create your Direct3D 12 resources&mdash;the Direct3D 12 device, command queue, command list, and resources such as descriptor heaps.</span></span>
2. <span data-ttu-id="e9aa4-147">Poiché si sta effettuando l'inferenza di machine learning oltre al carico di lavoro di rendering, creare risorse DirectML &mdash; il dispositivo DirectML e le istanze dell'operatore.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-147">Since you're doing machine learning inferencing as well as your rendering workload, create DirectML resources&mdash;the DirectML device, and operator instances.</span></span> <span data-ttu-id="e9aa4-148">Se si dispone di un modello di apprendimento automatico in cui è necessario eseguire un particolare tipo di convoluzione con una determinata dimensione del tensore di filtro con un particolare tipo di dati, questi sono tutti parametri nell'operatore di **convoluzione** di DirectML.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-148">If you have a machine learning model where you need to perform a particular type of convolution with a particular size of filter tensor with a particular data type, then those are all parameters into DirectML's **convolution** operator.</span></span>
3. <span data-ttu-id="e9aa4-149">DirectML registra il lavoro negli elenchi di comandi Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-149">DirectML records work into Direct3D 12 command lists.</span></span> <span data-ttu-id="e9aa4-150">Quindi, una volta completata l'inizializzazione, si registra l'associazione e l'inizializzazione di (ad esempio) l'operatore di convoluzione nell'elenco dei comandi.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-150">So, once initialization is done, you record the binding and initialization of (for example) your convolution operator into your command list.</span></span> <span data-ttu-id="e9aa4-151">Quindi, chiudere ed eseguire l'elenco dei comandi nella coda come di consueto.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-151">Then, close and execute your command list on your queue as usual.</span></span>

### <a name="execution"></a><span data-ttu-id="e9aa4-152">Esecuzione</span><span class="sxs-lookup"><span data-stu-id="e9aa4-152">Execution</span></span>

1. <span data-ttu-id="e9aa4-153">Caricare i tensori di peso in risorse.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-153">Upload your weight tensors into resources.</span></span> <span data-ttu-id="e9aa4-154">Un tensore in DirectML viene rappresentato usando una risorsa Direct3D 12 normale.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-154">A tensor in DirectML is represented using a regular Direct3D 12 resource.</span></span> <span data-ttu-id="e9aa4-155">Se, ad esempio, si desidera caricare i dati relativi al peso nella GPU, è possibile eseguire questa operazione esattamente come per qualsiasi altra risorsa Direct3D 12 (usare un heap di caricamento o la coda di copia).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-155">For example, if you want to upload your weight data to the GPU, then you do that the same way you would with any other Direct3D 12 resource (use an upload heap, or the copy queue).</span></span>
2. <span data-ttu-id="e9aa4-156">A questo punto, è necessario associare tali risorse di Direct3D 12 ai tensori di input e di output.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-156">Next, you need to bind those Direct3D 12 resources as your input and output tensors.</span></span> <span data-ttu-id="e9aa4-157">Registra nel comando elenca l'associazione e l'esecuzione degli operatori.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-157">Record into your command list the binding and the execution of your operators.</span></span>
3. <span data-ttu-id="e9aa4-158">Chiudere ed eseguire l'elenco dei comandi.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-158">Close and execute your command list.</span></span>

<span data-ttu-id="e9aa4-159">Analogamente a Direct3D 12, la durata delle risorse e la sincronizzazione sono responsabilità dell'utente.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-159">Just as with Direct3D 12, resource lifetime and synchronization are your responsibility.</span></span> <span data-ttu-id="e9aa4-160">Ad esempio, non rilasciare gli oggetti DirectML almeno fino a quando non è stata completata l'esecuzione nella GPU.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-160">For example, don't release your DirectML objects at least until they've completed execution on the GPU.</span></span>

## <a name="why-does-directml-perform-so-well"></a><span data-ttu-id="e9aa4-161">Perché DirectML viene eseguito correttamente?</span><span class="sxs-lookup"><span data-stu-id="e9aa4-161">Why does DirectML perform so well?</span></span>

<span data-ttu-id="e9aa4-162">C'è un buon motivo per cui non è sufficiente scrivere un proprio operatore di convoluzione (ad esempio) come HLSL in un [compute shader](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span><span class="sxs-lookup"><span data-stu-id="e9aa4-162">There's a good reason why you shouldn't just write your own convolution operator (for example) as HLSL in a [compute shader](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span></span> <span data-ttu-id="e9aa4-163">Il vantaggio dell'uso di DirectML è che &mdash; , oltre a risparmiare il lavoro di homebrewing per la propria soluzione, &mdash; offre la possibilità di ottenere prestazioni decisamente migliori rispetto a quanto possibile con uno shader di calcolo per utilizzo generico scritto manualmente per qualcosa di simile a **convoluzione** o **LSTM**.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-163">The advantage of using DirectML is that&mdash;apart from saving you the effort of homebrewing your own solution&mdash;it has the capability of giving you much better performance than you could achieve with a hand-written, general-purpose compute shader for something like **convolution**, or **lstm**.</span></span>

<span data-ttu-id="e9aa4-164">DirectML realizza questa operazione in parte grazie alla funzionalità per i metacomandi Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-164">DirectML achieves this in part due to the Direct3D 12 metacommands feature.</span></span> <span data-ttu-id="e9aa4-165">I metacomandi espongono una black box di funzionalità fino a DirectML, che consente ai fornitori di hardware di fornire l'accesso DirectML alle ottimizzazioni specifiche dell'architettura e dell'hardware del fornitore.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-165">Metacommands expose a black box of functionality up to DirectML, which allows hardware vendors to provide DirectML access to vendor hardware-specific and architecture-specific optimizations.</span></span> <span data-ttu-id="e9aa4-166">Più operatori &mdash; , ad esempio, la convoluzione seguita dall'attivazione &mdash; può essere *fusa* insieme in un singolo metacomando.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-166">Multiple operators&mdash;for example, convolution followed by activation&mdash;can be *fused* together into a single metacommand.</span></span> <span data-ttu-id="e9aa4-167">A causa di questi fattori, DirectML offre la possibilità di superare le prestazioni di un compute shader ottimizzato per la mano, scritto per l'esecuzione in un'ampia gamma di hardware.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-167">Because of these factors, DirectML has the capability to exceed the performance of even a very well-written hand-tuned compute shader written to run on a breadth of hardware.</span></span>

<span data-ttu-id="e9aa4-168">I metacomandi fanno parte dell'API Direct3D 12, anche se sono vagamente collegati.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-168">Metacommands are part of the Direct3D 12 API, although they're loosely coupled to it.</span></span> <span data-ttu-id="e9aa4-169">Un metacomando è identificato da un [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid)fisso, mentre quasi tutti gli altri elementi (dal comportamento e dalla semantica alla firma e al nome) non fanno parte dell'API Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-169">A metacommand is identified by a fixed [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid), while almost everything else about it (from its behavior and semantics to its signature and name) are not strictly part of the Direct3D 12 API.</span></span> <span data-ttu-id="e9aa4-170">Viene invece specificato un metacommand tra l'autore e il driver che lo implementa.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-170">Rather, a metacommand is specified between its author and the driver that implements it.</span></span> <span data-ttu-id="e9aa4-171">In questo caso, l'autore è DirectML.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-171">In this case, the author is DirectML.</span></span> <span data-ttu-id="e9aa4-172">I metacomandi sono primitivi Direct3D 12 (proprio come Draw e spedites), quindi possono essere registrati in un elenco di comandi e pianificati per l'esecuzione insieme.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-172">Metacommands are Direct3D 12 primitives (just like Draws and Dispatches), so they can be recorded into a command list and scheduled for execution together.</span></span>

<span data-ttu-id="e9aa4-173">DirectML accelera i carichi di lavoro di Machine Learning usando un'intera suite di metacomandi di machine learning.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-173">DirectML accelerates your machine learning workloads using an entire suite of machine learning metacommands.</span></span> <span data-ttu-id="e9aa4-174">Di conseguenza, non è necessario scrivere percorsi di codice specifici del fornitore per ottenere l'accelerazione hardware per l'inferenza.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-174">Consequently, you don't need to write vendor-specific code paths to achieve hardware acceleration for your inferencing.</span></span> <span data-ttu-id="e9aa4-175">Se l'esecuzione avviene su un chip accelerato per intelligenza artificiale, DirectML usa tale hardware per accelerare significativamente le operazioni, ad esempio la convoluzione.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-175">If you happen to run on an AI-accelerated chip, then DirectML uses that hardware to greatly accelerate operations such as convolution.</span></span> <span data-ttu-id="e9aa4-176">È possibile usare lo stesso codice scritto, senza modificarlo, eseguirlo su un chip non accelerato dall'intelligenza artificiale (probabilmente la GPU integrata nel computer portatile) e ottenere comunque un'accelerazione hardware GPU eccezionale.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-176">You can take the same code that you wrote, without modifying it, run it on a chip that's not AI-accelerated (perhaps the integrated GPU in your laptop), and still get great GPU hardware acceleration.</span></span> <span data-ttu-id="e9aa4-177">Se non è disponibile alcuna GPU, DirectML esegue il fallback alla CPU.</span><span class="sxs-lookup"><span data-stu-id="e9aa4-177">And if no GPU is available, then DirectML falls back to the CPU.</span></span>
