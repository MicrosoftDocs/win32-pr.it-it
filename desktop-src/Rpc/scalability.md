---
title: Scalabilità
description: Scalabilità
ms.assetid: 39327621-b536-4494-9319-9e9d4f534123
keywords:
- Scalabilità
- Remote Procedure Call RPC, procedure consigliate, scalabilità
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: 0728e35d9c9b27494014363c448be9965e39eea7
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 09/16/2019
ms.locfileid: "103856737"
---
# <a name="scalability"></a><span data-ttu-id="a782c-105">Scalabilità</span><span class="sxs-lookup"><span data-stu-id="a782c-105">Scalability</span></span>

<span data-ttu-id="a782c-106">Il termine, la scalabilità, viene spesso utilizzato in parte.</span><span class="sxs-lookup"><span data-stu-id="a782c-106">The term, scalability, is often misused.</span></span> <span data-ttu-id="a782c-107">Per questa sezione viene fornita una doppia definizione:</span><span class="sxs-lookup"><span data-stu-id="a782c-107">For this section, a dual definition is provided:</span></span>

-   <span data-ttu-id="a782c-108">La scalabilità è la capacità di usare completamente la potenza di elaborazione disponibile in un sistema multiprocessore (2, 4, 8, 32 o più processori).</span><span class="sxs-lookup"><span data-stu-id="a782c-108">Scalability is the ability to fully utilize available processing power on a multiprocessor system (2, 4, 8, 32, or more processors).</span></span>
-   <span data-ttu-id="a782c-109">La scalabilità è la capacità di servire un numero elevato di client.</span><span class="sxs-lookup"><span data-stu-id="a782c-109">Scalability is the ability to service a large number of clients.</span></span>

<span data-ttu-id="a782c-110">Queste due definizioni correlate sono comunemente definite *scalabilità verticale*.</span><span class="sxs-lookup"><span data-stu-id="a782c-110">These two related definitions are commonly referred to as *scaling up*.</span></span> <span data-ttu-id="a782c-111">Alla fine di questo argomento vengono forniti suggerimenti sulla *scalabilità orizzontale*.</span><span class="sxs-lookup"><span data-stu-id="a782c-111">The end of this topic provides tips about *scaling out*.</span></span>

<span data-ttu-id="a782c-112">Questo argomento è incentrato esclusivamente sulla scrittura di server scalabili, non di client scalabili, perché i server scalabili sono requisiti più comuni.</span><span class="sxs-lookup"><span data-stu-id="a782c-112">This discussion focuses exclusively on writing scalable servers, not scalable clients, because scalable servers are more common requirements.</span></span> <span data-ttu-id="a782c-113">Questa sezione risolve anche la scalabilità solo nel contesto dei server RPC e RPC.</span><span class="sxs-lookup"><span data-stu-id="a782c-113">This section also addresses scalability in the context of RPC and RPC servers only.</span></span> <span data-ttu-id="a782c-114">Le procedure consigliate per la scalabilità, ad esempio la riduzione della contesa, l'evitare i frequenti mancati riscontri nella cache nelle posizioni di memoria globale o l'evitare la falsa condivisione non vengono discusse qui</span><span class="sxs-lookup"><span data-stu-id="a782c-114">Best practices for scalability, such as reducing contention, avoiding frequent cache misses on global memory locations, or avoiding false sharing, are not discussed here.</span></span>

## <a name="rpc-threading-model"></a><span data-ttu-id="a782c-115">Modello di threading RPC</span><span class="sxs-lookup"><span data-stu-id="a782c-115">RPC Threading Model</span></span>

<span data-ttu-id="a782c-116">Quando una chiamata RPC viene ricevuta da un server, la routine del server (routine Manager) viene chiamata su un thread fornito da RPC.</span><span class="sxs-lookup"><span data-stu-id="a782c-116">When an RPC call is received by a server, the server routine (manager routine) is called on a thread supplied by RPC.</span></span> <span data-ttu-id="a782c-117">RPC utilizza un pool di thread adattivo che aumenta e diminuisce man mano che il carico di lavoro fluttua.</span><span class="sxs-lookup"><span data-stu-id="a782c-117">RPC uses an adaptive thread pool that increases and decreases as workload fluctuates.</span></span> <span data-ttu-id="a782c-118">A partire da Windows 2000, il nucleo del pool di thread RPC è una porta di completamento.</span><span class="sxs-lookup"><span data-stu-id="a782c-118">Starting with Windows 2000, the core of the RPC thread pool is a completion port.</span></span> <span data-ttu-id="a782c-119">La porta di completamento e l'utilizzo da parte di RPC sono ottimizzate per le routine del server con conflitti limitati.</span><span class="sxs-lookup"><span data-stu-id="a782c-119">The completion port and its usage by RPC are tuned for zero to low contention server routines.</span></span> <span data-ttu-id="a782c-120">Ciò significa che il pool di thread RPC aumenta in modo aggressivo il numero di thread di manutenzione se alcuni vengono bloccati.</span><span class="sxs-lookup"><span data-stu-id="a782c-120">This means that the RPC thread pool aggressively increases the number of servicing threads if some become blocked.</span></span> <span data-ttu-id="a782c-121">Opera sulla supposizione che il blocco sia raro e se un thread viene bloccato, si tratta di una condizione temporanea che viene rapidamente risolta.</span><span class="sxs-lookup"><span data-stu-id="a782c-121">It operates on the presumption that blocking is rare, and if a thread gets blocked, this is a temporary condition that is quickly resolved.</span></span> <span data-ttu-id="a782c-122">Questo approccio consente l'efficienza per i server con conflitti limitati.</span><span class="sxs-lookup"><span data-stu-id="a782c-122">This approach enables efficiency for low contention servers.</span></span> <span data-ttu-id="a782c-123">Ad esempio, un server RPC di chiamata void che opera su un server 550MHz a otto processori a cui si accede tramite una System Area Network ad alta velocità (SAN) serve oltre 30.000 chiamate void al secondo da oltre 200 client remoti.</span><span class="sxs-lookup"><span data-stu-id="a782c-123">For example, a void call RPC server operating on an eight-processor 550MHz server accessed over a high speed system area network (SAN) serves over 30,000 void calls per second from over 200 remote clients.</span></span> <span data-ttu-id="a782c-124">Rappresenta più di 108 milioni chiamate all'ora.</span><span class="sxs-lookup"><span data-stu-id="a782c-124">This represents more than 108 million calls per hour.</span></span>

<span data-ttu-id="a782c-125">Il risultato è che il pool di thread aggressivi viene effettivamente visualizzato quando la contesa sul server è elevata.</span><span class="sxs-lookup"><span data-stu-id="a782c-125">The result is that the aggressive thread pool actually gets in the way when contention on the server is high.</span></span> <span data-ttu-id="a782c-126">Per illustrare, si supponga di dover usare un server pesante per accedere ai file in modalità remota.</span><span class="sxs-lookup"><span data-stu-id="a782c-126">To illustrate, imagine a heavy-duty server used to remotely access files.</span></span> <span data-ttu-id="a782c-127">Si supponga che il server adotti l'approccio più semplice: legge/scrive semplicemente il file in modo sincrono sul thread sul quale RPC richiama la routine del server.</span><span class="sxs-lookup"><span data-stu-id="a782c-127">Assume the server adopts the most straightforward approach: it simply reads/writes the file synchronously on the thread on which that RPC invokes the server routine.</span></span> <span data-ttu-id="a782c-128">Si supponga inoltre di disporre di un server a quattro processori che serve molti client.</span><span class="sxs-lookup"><span data-stu-id="a782c-128">Also, assume we have a four-processor server serving many clients.</span></span>

<span data-ttu-id="a782c-129">Il server inizierà con cinque thread, che in realtà variano, ma per semplicità vengono usati cinque thread.</span><span class="sxs-lookup"><span data-stu-id="a782c-129">The server will start with five threads (this actually varies, but five threads is used for simplicity).</span></span> <span data-ttu-id="a782c-130">Quando RPC preleva la prima chiamata RPC, Invia la chiamata alla routine del server e la routine del server emette l'i/O.</span><span class="sxs-lookup"><span data-stu-id="a782c-130">Once RPC picks up the first RPC call, it dispatches the call to the server routine, and the server routine issues the I/O.</span></span> <span data-ttu-id="a782c-131">Raramente manca la cache dei file e quindi si blocca in attesa del risultato.</span><span class="sxs-lookup"><span data-stu-id="a782c-131">Infrequently, it misses the file cache and then blocks waiting for the result.</span></span> <span data-ttu-id="a782c-132">Non appena si blocca, il quinto thread viene rilasciato per prelevare una richiesta e un sesto thread viene creato come hot standby.</span><span class="sxs-lookup"><span data-stu-id="a782c-132">As soon as it blocks, the fifth thread is released to pick up a request, and a sixth thread is created as a hot standby.</span></span> <span data-ttu-id="a782c-133">Supponendo che ogni singola operazione di I/O riscontri la cache e si blocchi per 100 millisecondi (un valore di ora arbitrario) e presupponendo che il server a quattro processori serva circa 20.000 chiamate al secondo (5.000 chiamate per processore), una modellazione semplicistica stima che ogni processore genererà circa 50 thread.</span><span class="sxs-lookup"><span data-stu-id="a782c-133">Assuming each tenth I/O operation misses the cache and will block for 100 milliseconds (an arbitrary time value), and assuming the four-processor server serves about 20,000 calls per second (5,000 calls per processor), a simplistic modeling would predict that each processor will spawn approximately 50 threads.</span></span> <span data-ttu-id="a782c-134">Si presuppone che una chiamata che verrà bloccata ogni 2 millisecondi e, dopo 100 millisecondi, il primo thread venga liberato nuovamente, in modo che il pool si stabilizzi a circa 200 thread (50 per processore).</span><span class="sxs-lookup"><span data-stu-id="a782c-134">This assumes a call that will block comes every 2 milliseconds, and after 100 milliseconds the first thread is freed again so the pool will stabilize at about 200 threads (50 per processor).</span></span>

<span data-ttu-id="a782c-135">Il comportamento effettivo è più complesso, poiché il numero elevato di thread provocherà cambi di contesto aggiuntivi che rallentano il server e rallentano anche la frequenza di creazione di nuovi thread, ma l'idea di base è chiara.</span><span class="sxs-lookup"><span data-stu-id="a782c-135">The actual behavior is more complicated, as the high number of threads will cause extra context switches which slow the server, and also slow the rate of creation of new threads, but the basic idea is clear.</span></span> <span data-ttu-id="a782c-136">Il numero di thread aumenta rapidamente, perché i thread nel server iniziano a bloccarsi e in attesa di un elemento, ovvero un I/O o l'accesso a una risorsa.</span><span class="sxs-lookup"><span data-stu-id="a782c-136">The number of threads goes up quickly as threads on the server start blocking and waiting for something (be it an I/O, or access to a resource).</span></span>

<span data-ttu-id="a782c-137">RPC e la porta di completamento che consente di gestire le richieste in ingresso proveranno a mantenere il numero di thread RPC utilizzabili nel server in modo che corrispondano al numero di processori nel computer.</span><span class="sxs-lookup"><span data-stu-id="a782c-137">RPC and the completion port that gates incoming requests will try to maintain the number of usable RPC threads in the server to be equal to the number of processors on the machine.</span></span> <span data-ttu-id="a782c-138">Ciò significa che in un server a quattro processori, una volta che un thread torna a RPC, se sono presenti quattro o più thread RPC utilizzabili, il quinto thread non è autorizzato a prelevare una nuova richiesta e si troverà in uno stato di hot standby nel caso in cui uno dei blocchi di thread attualmente utilizzabili.</span><span class="sxs-lookup"><span data-stu-id="a782c-138">This means that on a four-processor server, once a thread returns to RPC, if there are four or more usable RPC threads, the fifth thread is not allowed to pick up a new request, and instead will sit in a hot standby state in case one of the currently usable threads blocks.</span></span> <span data-ttu-id="a782c-139">Se il quinto thread è in attesa di un tempo sufficiente come hot standby senza il numero di thread RPC utilizzabili che diminuiscono al di sotto del numero di processori, verrà rilasciato, ovvero, il pool di thread ridurrà.</span><span class="sxs-lookup"><span data-stu-id="a782c-139">If the fifth thread waits long enough as a hot standby without the number of usable RPC threads dropping below the number of processors, it will be released, that is, the thread pool will decrease.</span></span>

<span data-ttu-id="a782c-140">Immaginate un server con molti thread.</span><span class="sxs-lookup"><span data-stu-id="a782c-140">Imagine a server with many threads.</span></span> <span data-ttu-id="a782c-141">Come spiegato in precedenza, un server RPC termina con molti thread, ma solo se i thread si bloccano spesso.</span><span class="sxs-lookup"><span data-stu-id="a782c-141">As previously explained, an RPC server ends up with many threads, but only if the threads block often.</span></span> <span data-ttu-id="a782c-142">In un server in cui i thread si bloccano spesso, un thread che torna a RPC viene presto eliminato dall'elenco hot standby, perché tutti i thread attualmente utilizzabili vengono bloccati e viene fornita una richiesta di elaborazione.</span><span class="sxs-lookup"><span data-stu-id="a782c-142">On a server where threads often block, a thread that returns to RPC is soon taken out of the hot standby list, because all currently usable threads block, and is given a request to process.</span></span> <span data-ttu-id="a782c-143">Quando un thread si blocca, il dispatcher del thread nel kernel passa il contesto a un altro thread.</span><span class="sxs-lookup"><span data-stu-id="a782c-143">When a thread blocks, the thread dispatcher in the kernel switches context to another thread.</span></span> <span data-ttu-id="a782c-144">Questo cambio di contesto usa i cicli della CPU.</span><span class="sxs-lookup"><span data-stu-id="a782c-144">This context switch by itself consumes CPU cycles.</span></span> <span data-ttu-id="a782c-145">Il thread successivo eseguirà codice diverso, accederà a diverse strutture di dati e avrà uno stack diverso, il che significa che la percentuale di riscontri nella cache di memoria (le cache L1 e L2) sarà molto inferiore, causando un'esecuzione più lenta.</span><span class="sxs-lookup"><span data-stu-id="a782c-145">The next thread will be executing different code, accessing different data structures, and will have a different stack, which means the memory cache hit rate (the L1 and L2 caches) will be much lower, resulting in slower execution.</span></span> <span data-ttu-id="a782c-146">I numerosi thread in esecuzione contemporaneamente aumentano la contesa per le risorse esistenti, ad esempio heap, sezioni critiche nel codice del server e così via.</span><span class="sxs-lookup"><span data-stu-id="a782c-146">The numerous threads executing simultaneously increases contention for existing resources, such as heap, critical sections in the server code, and so on.</span></span> <span data-ttu-id="a782c-147">Questo aumenta ulteriormente la contesa come serie di istruzioni sul modulo delle risorse.</span><span class="sxs-lookup"><span data-stu-id="a782c-147">This further increases contention as convoys on resources form.</span></span> <span data-ttu-id="a782c-148">Se la memoria è insufficiente, la quantità di memoria utilizzata dal numero elevato e crescente di thread provocherà errori di pagina che aumentano ulteriormente la velocità con cui i thread vengono bloccati e comportano la creazione di più thread.</span><span class="sxs-lookup"><span data-stu-id="a782c-148">If memory is low, the memory pressure exerted by the large and growing number of threads will cause page faults, which further increase the rate at which the threads block, and cause even more threads to be created.</span></span> <span data-ttu-id="a782c-149">A seconda della frequenza con cui si blocca e della quantità di memoria fisica disponibile, è possibile che il server si stabilizzi a un livello inferiore di prestazioni con una frequenza di cambio di contesto elevata o che si verifichi un peggioramento fino al momento in cui si accede solo ripetutamente al disco rigido e al cambio di contesto senza eseguire alcuna operazione effettiva.</span><span class="sxs-lookup"><span data-stu-id="a782c-149">Depending on how often it blocks and how much physical memory is available, the server may either stabilize at some lower level of performance with a high context switch rate, or it may deteriorate to the point where it is only repeatedly accessing the hard disk and context switching without performing any actual work.</span></span> <span data-ttu-id="a782c-150">Questa situazione non verrà mostrata sotto un carico di lavoro leggero, ovviamente, ma un carico di lavoro pesante ridurrà rapidamente il problema alla superficie.</span><span class="sxs-lookup"><span data-stu-id="a782c-150">This situation will not show under light workload, of course, but a heavy workload quickly brings the problem to the surface.</span></span>

<span data-ttu-id="a782c-151">Come è possibile evitare questo problema?</span><span class="sxs-lookup"><span data-stu-id="a782c-151">How can this be prevented?</span></span> <span data-ttu-id="a782c-152">Se si prevede che i thread si blocchino, dichiarano chiamate come asincrone e una volta che la richiesta entra nella routine del server, accodarla a un pool di thread di lavoro che usano le funzionalità asincrone del sistema di I/o e/o RPC.</span><span class="sxs-lookup"><span data-stu-id="a782c-152">If threads are expected to block, declare calls as asynchronous, and once the request enters the server routine, queue it to a pool of worker threads that use the asynchronous capabilities of the I/O system and/or RPC.</span></span> <span data-ttu-id="a782c-153">Se il server è a sua volta, le chiamate RPC le rendono asincrone e assicurano che la coda non diventi troppo grande.</span><span class="sxs-lookup"><span data-stu-id="a782c-153">If the server is in turn making RPC calls make those asynchronous, and make sure the queue does not grow too large.</span></span> <span data-ttu-id="a782c-154">Se la routine del server esegue l'I/O dei file, utilizzare l'I/O di file asincrono per accodare più richieste al sistema di I/O e fare in modo che solo pochi thread vengano accodati e prelevino i risultati.</span><span class="sxs-lookup"><span data-stu-id="a782c-154">If the server routine is performing file I/O, use asynchronous file I/O to queue multiple requests to the I/O system and have only a few threads queue them and pick up the results.</span></span> <span data-ttu-id="a782c-155">Se la routine del server sta eseguendo l'I/O di rete, utilizzare di nuovo le funzionalità asincrone del sistema per emettere le richieste e prelevare le risposte in modo asincrono e utilizzare il minor numero di thread possibile.</span><span class="sxs-lookup"><span data-stu-id="a782c-155">If the server routine is doing network I/O, again, use the asynchronous capabilities of the system to issue the requests and pick up the replies asynchronously, and use as few threads as possible.</span></span> <span data-ttu-id="a782c-156">Quando viene eseguita l'operazione di i/O o la chiamata RPC eseguita dal server è stata completata, completare la chiamata RPC asincrona che ha recapitato la richiesta.</span><span class="sxs-lookup"><span data-stu-id="a782c-156">When the I/O is done, or the RPC call the server made is complete, complete the asynchronous RPC call that delivered the request.</span></span> <span data-ttu-id="a782c-157">Ciò consentirà al server di essere eseguito con il minor numero di thread possibile, aumentando così le prestazioni e il numero di client che un server è in grado di gestire.</span><span class="sxs-lookup"><span data-stu-id="a782c-157">This will enable the server to run with as few threads as possible, which increases the performance and the number of clients a server can service.</span></span>

## <a name="scale-out"></a><span data-ttu-id="a782c-158">Aumento del numero di istanze</span><span class="sxs-lookup"><span data-stu-id="a782c-158">Scale Out</span></span>

<span data-ttu-id="a782c-159">È possibile configurare RPC per l'utilizzo di bilanciamento carico di rete (NLB) se NLB è configurato in modo tale che tutte le richieste provenienti da un determinato indirizzo client vadano allo stesso server.</span><span class="sxs-lookup"><span data-stu-id="a782c-159">RPC can be configured to work with Network Load Balancing (NLB) if NLB is configured such that all requests from a given client address go to the same server.</span></span> <span data-ttu-id="a782c-160">Poiché ogni client RPC apre un pool di connessioni (per altre informazioni, vedere [RPC e la rete](rpc-and-the-network.md)), è essenziale che tutte le connessioni dal pool del client specificato si trovino nello stesso computer server.</span><span class="sxs-lookup"><span data-stu-id="a782c-160">Because each RPC client opens a connection pool (for more information, see [RPC and the Network](rpc-and-the-network.md)), it is essential that all connections from the pool of the given client end up on the same server computer.</span></span> <span data-ttu-id="a782c-161">Fino a quando questa condizione viene soddisfatta, è possibile configurare un cluster NLB in modo che funzioni come un server RPC di grandi dimensioni con scalabilità potenzialmente eccellente.</span><span class="sxs-lookup"><span data-stu-id="a782c-161">As long as this condition is met, an NLB cluster can be configured to function as one large RPC server with potentially excellent scalability.</span></span>

 

 




